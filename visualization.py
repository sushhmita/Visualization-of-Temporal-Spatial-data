# -*- coding: utf-8 -*-
"""DHV PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_bUgrVWQJ_V5l5ppuV9dv1kff4m4SKbV
"""

!pip install contextily

import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
from shapely.geometry import Point
import contextily as ctx  # For basemaps
import seaborn as sns

print(df.columns)

df = pd.read_csv('/content/train.csv')

df.head()

# Convert timestamp to datetime
df['timestep'] = pd.to_datetime(df['timestep'])

# Filter data for a specific time range (optional)
df = df[(df['timestep'] >= '2024-01-01') & (df['timestep'] <= '2024-01-07')]

import numpy as np
df['latitude'] = np.random.uniform(low=10, high=50, size=len(df))
df['longitude'] = np.random.uniform(low=-120, high=-70, size=len(df))

# Create a GeoDataFrame
geometry = [Point(xy) for xy in zip(df['longitude'], df['latitude'])]
gdf = gpd.GeoDataFrame(df, geometry=geometry, crs="EPSG:4326")  # WGS84 coordinate system

# Convert to Web Mercator for basemap compatibility
gdf = gdf.to_crs(epsg=3857)

print(df[['latitude', 'longitude']].head())

import numpy as np

# Add a synthetic 'vehicle_count' column with random values
df['vehicle_count'] = np.random.randint(50, 500, size=len(df))
print(df.head())

# Aggregate traffic from previous data columns
df['vehicle_count'] = df[['prev_1', 'prev_2', 'prev_3']].sum(axis=1)
print(df.head())

# Map traffic levels to approximate vehicle counts
traffic_mapping = {'low': 100, 'medium': 300, 'high': 600}  # Example mapping
df['vehicle_count'] = df['traffic'].map(traffic_mapping)
print(df.head())

# Example: Merging external data
external_data = pd.DataFrame({
    'location': ['Loc1', 'Loc2', 'Loc3'],
    'vehicle_count': [300, 450, 600]
})
df = df.merge(external_data, on='location', how='left')
print(df.head())

print(gdf.head())  # Check the first few rows
print(gdf.info())  # Check for empty or missing values

import pandas as pd
import numpy as np
from shapely.geometry import Point
import geopandas as gpd
import contextily as ctx
import matplotlib.pyplot as plt

# Example dataset with latitude and longitude (adjust with your data)
df = pd.DataFrame({
    'longitude': np.random.uniform(-120, -70, 100),
    'latitude': np.random.uniform(10, 50, 100)
})

# Add a synthetic 'vehicle_count' column
df['vehicle_count'] = np.random.randint(50, 500, size=len(df))

# Check for missing values
print(df[['longitude', 'latitude', 'vehicle_count']].isnull().sum())

# Drop rows with missing values (if any)
df = df.dropna(subset=['longitude', 'latitude', 'vehicle_count'])
print(df.shape)

# Convert DataFrame to GeoDataFrame
df['geometry'] = df.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)
gdf = gpd.GeoDataFrame(df, geometry='geometry', crs="EPSG:4326")

# Reproject to Web Mercator for basemap compatibility
gdf = gdf.to_crs(epsg=3857)

# Plot with basemap
ax = gdf.plot(column='vehicle_count', cmap='viridis', legend=True, markersize=20, alpha=0.7, figsize=(10, 8))
ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)  # Use OpenStreetMap basemap
plt.title('Traffic Flow Heatmap')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.show()

df.columns = df.columns.str.strip()

print(df.head())  # Display first few rows to check for date/time columns
print(df.columns)  # Display all column names to look for a date or time column

# Assuming 'vehicle_count' is your total vehicle count for an hour:
df['hour_of_day'] = np.random.randint(0, 24, size=len(df))  # Create a dummy hour_of_day column
df.rename(columns={'vehicle_count': 'total_vehicle_count'}, inplace=True) # Rename if necessary

# Ensure there are no missing values in the relevant columns
print(df[['hour_of_day', 'total_vehicle_count']].isnull().sum())

# Check the unique values in the hour_of_day column
print(df['hour_of_day'].unique())

# Try grouping by hour_of_day and summing the total_vehicle_count
hourly_traffic = df.groupby('hour_of_day')['total_vehicle_count'].sum()

# Check the aggregated data
print(hourly_traffic)

# Plot again
hourly_traffic.plot(kind='bar', x='hour_of_day', y='total_vehicle_count', title='Hourly Traffic Flow')  # Changed to bar plot for better visualization
plt.xlabel('Hour of Day')
plt.ylabel('Total Vehicle Count')
plt.show()

# Example dataset with latitude and longitude (adjust with your data)
df = pd.DataFrame({
    'longitude': np.random.uniform(-120, -70, 100),
    'latitude': np.random.uniform(10, 50, 100)
})

# Add a synthetic 'vehicle_count' column
df['vehicle_count'] = np.random.randint(50, 500, size=len(df))

# Add a synthetic 'timestep' column with datetime values
# Make sure to adjust the date range and frequency if needed
df['timestep'] = pd.date_range(start='2023-11-01', periods=len(df), freq='H')

# Check for missing values
print(df[['longitude', 'latitude', 'vehicle_count']].isnull().sum())

# Drop rows with missing values (if any)
df = df.dropna(subset=['longitude', 'latitude', 'vehicle_count'])
print(df.shape)

# Convert DataFrame to GeoDataFrame
df['geometry'] = df.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)
gdf = gpd.GeoDataFrame(df, geometry='geometry', crs="EPSG:4326")

# Reproject to Web Mer

# 3. Daily Traffic Flow Analysis
df['date'] = df['timestep'].dt.date
daily_traffic = df.groupby('date')['vehicle_count'].sum().reset_index()

plt.figure(figsize=(10, 6))
sns.barplot(data=daily_traffic, x='date', y='vehicle_count', palette='Blues')
plt.xticks(rotation=45)
plt.title('Daily Traffic Flow')
plt.xlabel('Date')
plt.ylabel('Total Vehicle Count')
plt.grid(True)
plt.show()